# Concrete Strength Predictor

PrÃ©diction de la rÃ©sistance (en compression simple) du bÃ©ton Ã  partir de sa composition et durÃ©e de cure, via l'API FastAPI et un dashboard bord Streamlit. 
Le projet inclut aussi une base PostgreSQL pour le stockage du dataset d'entrainement du modÃ¨le ML.

---

## ğŸ§± Description

Ce projet propose une application complÃ¨te pour :

- Ingestion, nettoyage et stockage des donnÃ©es bÃ©ton dans une base PostgreSQL.
- EntraÃ®nement de differents modÃ¨les de machine learning et sauvegarde du meilleur (XGBoost) pour prÃ©dire la rÃ©sistance Ã  la compression du bÃ©ton.
- API REST avec FastAPI pour exposer les prÃ©dictions individuelles et batch.
- Dashboard Streamlit pour une interface utilisateur simple permettant dâ€™effectuer des prÃ©dictions.

---

## ğŸš€ FonctionnalitÃ©s

- PrÃ©diction individuelle via formulaire web.
- PrÃ©diction batch via import de fichier CSV.
- Stockage des donnÃ©es et modÃ¨les dans des dossiers dÃ©diÃ©s.
- Conteneurisation via Docker avec orchestration docker-compose.

---

## ğŸ“‚ Structure du projet
.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ predictions
â”‚   â”‚   â””â”€â”€ predicted_strength.csv
â”‚   â”œâ”€â”€ processed
â”‚   â”‚   â””â”€â”€ concrete_data_clean.csv
â”‚   â””â”€â”€ raw
â”‚       â”œâ”€â”€ concrete_data.csv
â”‚       â””â”€â”€ concrete_data.xls
â”œâ”€â”€ docker
â”‚   â”œâ”€â”€ api
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ dashboard
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ LICENSE
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ best_model.joblib
â”‚   â””â”€â”€ xgboost_model.joblib
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â””â”€â”€ 02_modeling.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ script
â”‚   â””â”€â”€ run_app.sh
â””â”€â”€ src
    â”œâ”€â”€ api
    â”‚   â”œâ”€â”€ main.py
    â”‚   â”œâ”€â”€ model_loader.py
    â”‚   â”œâ”€â”€ __pycache__
    â”‚   â””â”€â”€ schemas.py
    â”œâ”€â”€ dashboard
    â”‚   â”œâ”€â”€ app.py
    â”‚   â”œâ”€â”€ components.py
    â”‚   â”œâ”€â”€ __pycache__
    â”‚   â””â”€â”€ static
    â”œâ”€â”€ etl
    â”‚   â”œâ”€â”€ 1-download_data.py
    â”‚   â”œâ”€â”€ 2-clean_data.py
    â”‚   â”œâ”€â”€ 3-load_to_db.py
    â”‚   â””â”€â”€ __init__.py
    â””â”€â”€ ml
        â”œâ”€â”€ 1-train_model.py
        â”œâ”€â”€ 2-predict.py
        â”œâ”€â”€ 3-evaluate_model.py
        â””â”€â”€ __init__.py

---

## ğŸ› ï¸ PrÃ©requis

- Docker et Docker Compose installÃ©s
- [Make](https://www.gnu.org/software/make/) (optionnel, pour simplifier certaines commandes)
- Variables d'environnement dans un fichier `.env` 

---

## âš™ï¸ Configuration

CrÃ©ez un fichier `.env` Ã  la racine du projet avec le contenu suivant (Ã  adapter) :
    POSTGRES_DB=concrete_db
    POSTGRES_USER=concrete_user
    POSTGRES_PASSWORD=your_password
    API_URL=http://localhost:8000

---

## ğŸš€ DÃ©marrage local avec Docker

Pour lancer tous les services (PostgreSQL, API FastAPI, Dashboard Streamlit) depuis la racine du projet:

```bash
docker-compose docker compose up --build
